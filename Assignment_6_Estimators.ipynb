{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 6 -  Estimators.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devangi2000/Deep-Learning/blob/master/Assignment_6_Estimators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltd9Ar449-cl"
      },
      "source": [
        "### **Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtRIELH_97Ro"
      },
      "source": [
        "Install and import all the necessary libraries for the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG3_4ZU0_OE9"
      },
      "source": [
        "seed = 1\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "import random as rn\n",
        "rn.seed(seed)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ83YONE97Rs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns_colors = sns.color_palette('colorblind')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2h0X-5v97R3"
      },
      "source": [
        "### **Importing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L25L1OIK97R6"
      },
      "source": [
        "boston_dataset = load_boston()\n",
        "\n",
        "data_X = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
        "data_Y = pd.DataFrame(boston_dataset.target, columns=[\"target\"])\n",
        "data = pd.concat([data_X, data_Y], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wOjFmUJ97SD"
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.25, random_state=7)\n",
        "print(len(train), \"train examples\")\n",
        "print(len(test), \"test examples\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9bNY19D97SP"
      },
      "source": [
        "Converting the Pandas DataFrames into Tensorflow Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbejh2Wp97SS"
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle_and_repeat=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle_and_repeat:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.repeat()\n",
        "    \n",
        "  ds = ds.batch(batch_size)\n",
        "  \n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G49Lkx5497Sd"
      },
      "source": [
        "### Defining Feature Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N-7Cuak97Sf"
      },
      "source": [
        "# define feature_columns as a list of all the features except 'RAD' as numeric columns using functions from tf.feature_column\n",
        "# bucketize the ‘RAD’ column with the boundaries parameter as [2, 5] \n",
        "feature_columns = []\n",
        "\n",
        "NUMERIC_COLUMNS = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS',\n",
        "       'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['RAD']\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7f071ckBaqp"
      },
      "source": [
        "price = tf.feature_column.numeric_column('RAD')\n",
        "bucketized_price = tf.feature_column.bucketized_column(price, boundaries=[2,5])\n",
        "feature_columns.append(bucketized_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z585fT0N97Sm"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEDD1ZAh97So"
      },
      "source": [
        "config = tf.estimator.RunConfig(tf_random_seed=seed)\n",
        "\n",
        "\n",
        "# Build the model using tf.estimator and pass as config variable to the config parameter of the estimator\n",
        "model = tf.estimator.BoostedTreesRegressor(feature_columns = feature_columns,n_batches_per_layer=1, center_bias=True, config = config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7kUZnP997Sv"
      },
      "source": [
        "Train the model by using the df_to_dataset function. Batch size should be 32. Note that while training the model, the shuffle_and_repeat parameter of the df_to_dataset function should be set to True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjF6Rq7-Cxv7"
      },
      "source": [
        "# Train the model\n",
        "model.train(input_fn = lambda:df_to_dataset(train), steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEKmcvBQEDRO"
      },
      "source": [
        "# Evaluate the model using the df_to_dataset function and the test dataframe\n",
        "result = model.evaluate(input_fn = lambda: df_to_dataset(test), steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_dyVU8-POff"
      },
      "source": [
        "### **Boosted Trees Interpretation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UUEX6UyPDIy"
      },
      "source": [
        "You will need this section only for questions 5-7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIL93B4sDRqE"
      },
      "source": [
        "pred_dicts = list(model.experimental_predict_with_explanations(lambda: df_to_dataset(test, False, 32)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDPoRx_ZaY1E"
      },
      "source": [
        "# Create DFC Pandas dataframe.\n",
        "predictions = pd.Series([pred['predictions'][0] for pred in pred_dicts])\n",
        "df_dfc = pd.DataFrame([pred['dfc'] for pred in pred_dicts])\n",
        "df_dfc.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd9VuizRaY1H"
      },
      "source": [
        "# Sum of DFCs + bias == probabality.\n",
        "bias = pred_dicts[0]['bias']\n",
        "dfc_pred = df_dfc.sum(axis=1) + bias\n",
        "np.testing.assert_almost_equal(dfc_pred.values,\n",
        "                               predictions.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z_Tq1Pquczj"
      },
      "source": [
        "# Boilerplate code for plotting :)\n",
        "def _get_color(value):\n",
        "    \"\"\"To make positive DFCs plot green, negative DFCs plot red.\"\"\"\n",
        "    green, red = sns.color_palette()[2:4]\n",
        "    if value >= 0: return green\n",
        "    return red\n",
        "\n",
        "def _add_feature_values(feature_values, ax):\n",
        "    \"\"\"Display feature's values on left of plot.\"\"\"\n",
        "    x_coord = ax.get_xlim()[0]\n",
        "    OFFSET = 0.15\n",
        "    for y_coord, (feat_name, feat_val) in enumerate(feature_values.items()):\n",
        "        t = plt.text(x_coord, y_coord - OFFSET, '{}'.format(feat_val), size=12)\n",
        "        t.set_bbox(dict(facecolor='white', alpha=0.5))\n",
        "    from matplotlib.font_manager import FontProperties\n",
        "    font = FontProperties()\n",
        "    font.set_weight('bold')\n",
        "    t = plt.text(x_coord, y_coord + 1 - OFFSET, 'feature\\nvalue',\n",
        "    fontproperties=font, size=12)\n",
        "\n",
        "def plot_example(example):\n",
        "  TOP_N = 8 # View top 8 features.\n",
        "  sorted_ix = example.abs().sort_values()[-TOP_N:].index  # Sort by magnitude.\n",
        "  example = example[sorted_ix]\n",
        "  colors = example.map(_get_color).tolist()\n",
        "  ax = example.to_frame().plot(kind='barh',\n",
        "                          color=[colors],\n",
        "                          legend=None,\n",
        "                          alpha=0.75,\n",
        "                          figsize=(10,6))\n",
        "  ax.grid(False, axis='y')\n",
        "  ax.set_yticklabels(ax.get_yticklabels(), size=14)\n",
        "\n",
        "  # Add feature values.\n",
        "  _add_feature_values(test.iloc[ID][sorted_ix], ax)\n",
        "  return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht1P2-1euczk"
      },
      "source": [
        "# Plot results.\n",
        "ID = 10\n",
        "example = df_dfc.iloc[ID]  # Choose ith example from evaluation set.\n",
        "TOP_N = 8  # View top 8 features.\n",
        "sorted_ix = example.abs().sort_values()[-TOP_N:].index\n",
        "ax = plot_example(example)\n",
        "ax.set_title('Feature contributions for example {}\\n pred: {:1.2f};'.format(ID, predictions[ID]))\n",
        "ax.set_xlabel('Contribution to prediction', size=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo7rNd1v_5e2"
      },
      "source": [
        "# Boilerplate plotting code.\n",
        "def dist_violin_plot(df_dfc, ID):\n",
        "  # Initialize plot.\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "  # Create example dataframe.\n",
        "  TOP_N = 8  # View top 8 features.\n",
        "  example = df_dfc.iloc[ID]\n",
        "  ix = example.abs().sort_values()[-TOP_N:].index\n",
        "  example = example[ix]\n",
        "  example_df = example.to_frame(name='dfc')\n",
        "\n",
        "  # Add contributions of entire distribution.\n",
        "  parts=ax.violinplot([df_dfc[w] for w in ix],\n",
        "                 vert=False,\n",
        "                 showextrema=False,\n",
        "                 widths=0.7,\n",
        "                 positions=np.arange(len(ix)))\n",
        "  face_color = sns_colors[0]\n",
        "  alpha = 0.15\n",
        "  for pc in parts['bodies']:\n",
        "      pc.set_facecolor(face_color)\n",
        "      pc.set_alpha(alpha)\n",
        "\n",
        "  # Add feature values.\n",
        "  _add_feature_values(test.iloc[ID][sorted_ix], ax)\n",
        "\n",
        "  # Add local contributions.\n",
        "  ax.scatter(example,\n",
        "              np.arange(example.shape[0]),\n",
        "              color=sns.color_palette()[2],\n",
        "              s=100,\n",
        "              marker=\"s\",\n",
        "              label='contributions for example')\n",
        "\n",
        "  # Legend\n",
        "  # Proxy plot, to show violinplot dist on legend.\n",
        "  ax.plot([0,0], [1,1], label='eval set contributions\\ndistributions',\n",
        "          color=face_color, alpha=alpha, linewidth=10)\n",
        "  legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large',\n",
        "                     frameon=True)\n",
        "  legend.get_frame().set_facecolor('white')\n",
        "\n",
        "  # Format plot.\n",
        "  ax.set_yticks(np.arange(example.shape[0]))\n",
        "  ax.set_yticklabels(example.index)\n",
        "  ax.grid(False, axis='y')\n",
        "  ax.set_xlabel('Contribution to prediction', size=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkCqraA2uczm"
      },
      "source": [
        "dist_violin_plot(df_dfc, ID)\n",
        "plt.title('Feature contributions for example {}\\n pred: {:1.2f}'.format(ID, predictions[ID]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ocBcMatuczs"
      },
      "source": [
        "### Gain-based feature importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPTxbAaeuczt"
      },
      "source": [
        "importances = model.experimental_feature_importances(normalize=True)\n",
        "df_imp = pd.Series(importances)\n",
        "\n",
        "# Visualize importances.\n",
        "N = 8\n",
        "ax = (df_imp.iloc[0:N][::-1]\n",
        "    .plot(kind='barh',\n",
        "          color=sns_colors[0],\n",
        "          title='Gain feature importances',\n",
        "          figsize=(10, 6)))\n",
        "ax.grid(False, axis='y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0k_DvPLaY1o"
      },
      "source": [
        "You can also see how DFCs vary as a feature value varies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcIfN1IpaY1o"
      },
      "source": [
        "FEATURE = 'LSTAT'\n",
        "feature = pd.Series(df_dfc[FEATURE].values, index=test[FEATURE].values).sort_index()\n",
        "ax = sns.regplot(feature.index.values, feature.values, lowess=True)\n",
        "ax.set_ylabel('contribution')\n",
        "ax.set_xlabel(FEATURE)\n",
        "ax.set_xlim(0, 35)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFv0u6xrGlg7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}