{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAE5E6JN_c6o"
      },
      "source": [
        "\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpwZxfx-_jBO"
      },
      "source": [
        "class RBM():\r\n",
        "\r\n",
        "#   Parameters\r\n",
        "\r\n",
        "#   n_v             :   Number of visible inputs\r\n",
        "#                       Initialized by 0 but then take value of number of inputs\r\n",
        "#   n_h             :   Number of features want to extract\r\n",
        "#                       Must be set by user\r\n",
        "#   k               :   Sampling steps for contrastive divergance\r\n",
        "#                       Default value is 2 steps\r\n",
        "#   epochs          :   Number of epochs for training RBM\r\n",
        "#                       Must be set by user\r\n",
        "#   mini_batch_size :   Size of mini batch for training\r\n",
        "#                       Must be set by user\r\n",
        "#   alpha           :   Learning rate for updating parameters of RBM\r\n",
        "#                       Default value is 0.001\r\n",
        "#   momentum        :   Reduces large jumps for updating parameters\r\n",
        "#   weight_decay    :   Reduces the value of weight after every step of contrastive divergance\r\n",
        "#   data            :   Data to be fitted for RBM\r\n",
        "#                       Must be given by user or else, thats all useless\r\n",
        "    \r\n",
        "    def __init__(self, n_v=0, n_h=0, k=2, epochs=15, mini_batch_size=64, alpha=0.001, momentum=0.9, weight_decay=0.001):\r\n",
        "        self.number_features = 0\r\n",
        "        self.n_v             = n_v\r\n",
        "        self.n_h             = self.number_features\r\n",
        "        self.k               = k\r\n",
        "        self.alpha           = alpha\r\n",
        "        self.momentum        = momentum\r\n",
        "        self.weight_decay    = weight_decay\r\n",
        "        self.mini_batch_size = mini_batch_size\r\n",
        "        self.epochs          = epochs\r\n",
        "        self.data            = torch.randn(1, device=\"cuda\")\r\n",
        "\r\n",
        "#   fit            method is called to fit RBM for provided data\r\n",
        "#                  First, data is converted in range of 0-1 cuda float tensors by dividing it by their maximum value\r\n",
        "#                  Here, after calling this method, n_v is reinitialized to number of input values present in data\r\n",
        "#                  number_features must be given by user before calling this method\r\n",
        "#   w              Tensor of weights of RBM\r\n",
        "#                  (n_v x n_h)    Randomly initialized between 0-1\r\n",
        "#   a              Tensor of bias for visible units\r\n",
        "#                  (n_v x 1)      Initialized by 1's\r\n",
        "#   b              Tensor of bias for hidden units\r\n",
        "#                  (n_b x 1)      Initialized by 1's\r\n",
        "#   w_moment       Momentum value for weights\r\n",
        "#                  (n_v x n_h)    Initialized by zeros\r\n",
        "#   a_moment       Momentum values for visible units\r\n",
        "#                  (n_v x 1)      Initialized by zeros\r\n",
        "#   b_moment       Momentum values for hidden units\r\n",
        "#                  (n_h x 1)      Initialized by zeros\r\n",
        "    def fit(self):\r\n",
        "        \r\n",
        "        self.data /= self.data.max()\r\n",
        "        \r\n",
        "        self.data = self.data.type(torch.cuda.FloatTensor)\r\n",
        "        \r\n",
        "        self.n_v = len(self.data[0])\r\n",
        "        self.n_h = self.number_features\r\n",
        "        \r\n",
        "        self.w = torch.randn(self.n_v, self.n_h, device=\"cuda\") * 0.1\r\n",
        "        self.a = torch.ones(self.n_v, device=\"cuda\") * 0.5\r\n",
        "        self.b = torch.ones(self.n_h, device=\"cuda\")\r\n",
        "        self.w_moment = torch.zeros(self.n_v, self.n_h, device=\"cuda\")\r\n",
        "        self.a_moment = torch.zeros(self.n_v, device=\"cuda\")\r\n",
        "        self.b_moment = torch.zeros(self.n_h, device=\"cuda\")\r\n",
        "        \r\n",
        "        self.train()\r\n",
        "\r\n",
        "#   train          This method splits dataset into mini_batch and run for given epoch number of times\r\n",
        "    def train(self):\r\n",
        "        for epoch_no in range(self.epochs):\r\n",
        "            ep_error = 0\r\n",
        "            for i in range(0, len(self.data), self.mini_batch_size):\r\n",
        "                mini_batch = self.data[i:i+self.mini_batch_size]\r\n",
        "                ep_error += self.contrastive_divergence(mini_batch)\r\n",
        "            print(\"Epoch Number  : \", epoch_no, \"       Error  : \", ep_error.item())\r\n",
        "\r\n",
        "#   cont_diverg    It performs contrastive divergance using gibbs sampling algorithm\r\n",
        "#   p_h_0          Value of hidden units for given visivle units\r\n",
        "#   h_0            Activated hidden units as sampled from normal distribution (0 or 1)\r\n",
        "#   g_0            Positive associations of RBM\r\n",
        "#   wv_a           Unactivated hidden units\r\n",
        "#   p_v_h          Probability of hidden neuron to be activated given values of visible neurons\r\n",
        "#   p_h_v          Probability of visible neuron to be activated given values of hidden neurons\r\n",
        "#   p_v_k          Value of visible units for given visivle units after k step Gibbs Sampling\r\n",
        "#   p_h_k          Value of hidden units for given visivle units after k step Gibbs Sampling\r\n",
        "#   g_k            Negative associations of RBM\r\n",
        "#   error          Recontruction error for given mini_batch\r\n",
        "    def contrastive_divergence(self, v):\r\n",
        "        p_h_0 = self.sample_hidden(v)\r\n",
        "        h_0   = (p_h_0 >= torch.rand(self.n_h, device=\"cuda\")).float()\r\n",
        "        g_0   = v.transpose(0, 1).mm(h_0)\r\n",
        "\r\n",
        "        wv_a = h_0\r\n",
        "#       Gibbs Sampling step\r\n",
        "        for step in range(self.k):\r\n",
        "            p_v_h = self.sample_visible(wv_a)\r\n",
        "            p_h_v = self.sample_hidden(p_v_h)\r\n",
        "            wv_a  = (p_h_v >= torch.rand(self.n_h, device=\"cuda\")).float()\r\n",
        "\r\n",
        "        p_v_k = p_v_h\r\n",
        "        p_h_k = p_h_v\r\n",
        "\r\n",
        "        g_k = p_v_k.transpose(0, 1).mm(p_h_k)\r\n",
        "\r\n",
        "        self.update_parameters(g_0, g_k, v, p_v_k, p_h_0, p_h_k)\r\n",
        "\r\n",
        "        error = torch.sum((v - p_v_k)**2)\r\n",
        "\r\n",
        "        return error\r\n",
        "\r\n",
        "#   p_v_h     :   Probability of hidden neuron to be activated given values of visible neurons\r\n",
        "#   p_h_v     :   Probability of visible neuron to be activated given values of hidden neurons\r\n",
        "\r\n",
        "#-----------------------------------Bernoulli-Bernoulli RBM--------------------------------------------\r\n",
        "#   p_h_v    =    sigmoid ( weight  x visible  +  visible_bias )\r\n",
        "#   p_v_h    =    sigmoid (weight.t x hidden   +  hidden_bias )\r\n",
        "#------------------------------------------------------------------------------------------------------\r\n",
        "    def sample_hidden(self, p_v_h):  #   Bernoulli-Bernoulli RBM\r\n",
        "        wv    = p_v_h.mm(self.w)\r\n",
        "        wv_a  = wv + self.b\r\n",
        "        p_h_v = torch.sigmoid(wv_a)\r\n",
        "        return p_h_v\r\n",
        "\r\n",
        "    def sample_visible(self, p_h_v): #   Bernoulli-Bernoulli RBM\r\n",
        "        wh    = p_h_v.mm(self.w.transpose(0, 1))\r\n",
        "        wh_b  = wh + self.a\r\n",
        "        p_v_h = torch.sigmoid(wh_b)\r\n",
        "        return p_v_h\r\n",
        "\r\n",
        "#   weight_(t)        =     weight_(t)       +  ( positive_association  -  negative_association )  +  weight_(t-1)\r\n",
        "#   visible_bias_(t)  =     visible_bias_(t) +  sum( input - activated_visivle_at_k_step_sample )  +  visible_bias_(t-1)\r\n",
        "#   hidden_bias_(t)   =     hidden_bias_(t)  +  sum( activated_initial_hidden - activated_hidden_at_k_step_sample ) + hidden_bias_(t-1)\r\n",
        "    def update_parameters(self, g_0, g_k, v, p_v_k, p_h_0, p_h_k):\r\n",
        "        self.w_moment *= self.momentum\r\n",
        "        del_w          = (g_0 - g_k) + self.w_moment\r\n",
        "\r\n",
        "        self.a_moment *= self.momentum\r\n",
        "        del_a          = torch.sum(v - p_v_k, dim=0) + self.a_moment\r\n",
        "        self.b_moment *= self.momentum\r\n",
        "        del_b          = torch.sum(p_h_0 - p_h_k, dim=0) + self.b_moment\r\n",
        "\r\n",
        "        batch_size = v.size(0)\r\n",
        "\r\n",
        "        self.w += del_w * self.alpha / batch_size\r\n",
        "        self.a += del_a * self.alpha / batch_size\r\n",
        "        self.b += del_b * self.alpha / batch_size\r\n",
        "\r\n",
        "        self.w -= (self.w * self.weight_decay)\r\n",
        "        \r\n",
        "        self.w_moment = del_w\r\n",
        "        self.a_moment = del_a\r\n",
        "        self.b_moment = del_b"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xEYN7JGAY_r"
      },
      "source": [
        "import tensorflow as tf\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-eDEdZwAJQK"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\", header=None)\r\n",
        "data    = torch.tensor(np.array(dataset)[:, 1:], device=\"cuda\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSn8xZ3XAxJ5"
      },
      "source": [
        "mnist = RBM()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWl5JsdeBXBq"
      },
      "source": [
        "mnist.data = data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi4ecmCzB2pL"
      },
      "source": [
        "mnist.number_features = 300"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feSLfWQDB79F",
        "outputId": "9a66c3f4-a0fa-4920-d7db-e752fd46c928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "error = mnist.fit()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-eb1ac9ed290f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-54e978b99bf1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yueHG-KB8s3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}