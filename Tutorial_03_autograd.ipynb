{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial-03-autograd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfgmwKHdYMW0d0lruf0LJU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devangi2000/Deep-Learning/blob/master/Tutorial_03_autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOn8FeWg0Z9Q"
      },
      "source": [
        "### Link to PyTorch AutoGrad tutorial\n",
        "\n",
        "https://pytorch.org/docs/stable/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91T69jb80Fo4"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "def set_default(figsize=(10, 10), dpi=100):\n",
        "    plt.style.use(['dark_background', 'bmh'])\n",
        "    plt.rc('axes', facecolor='k')\n",
        "    plt.rc('figure', facecolor='k')\n",
        "    plt.rc('figure', figsize=figsize, dpi=dpi)\n",
        "\n",
        "\n",
        "def plot_data(X, y, d=0, auto=False, zoom=1):\n",
        "    X = X.cpu()\n",
        "    y = y.cpu()\n",
        "    plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=20, cmap=plt.cm.Spectral)\n",
        "    plt.axis('square')\n",
        "    plt.axis(np.array((-1.1, 1.1, -1.1, 1.1)) * zoom)\n",
        "    if auto is True: plt.axis('equal')\n",
        "    plt.axis('off')\n",
        "\n",
        "    _m, _c = 0, '.15'\n",
        "    plt.axvline(0, ymin=_m, color=_c, lw=1, zorder=0)\n",
        "    plt.axhline(0, xmin=_m, color=_c, lw=1, zorder=0)\n",
        "\n",
        "\n",
        "def plot_model(X, y, model):\n",
        "    model.cpu()\n",
        "    mesh = np.arange(-1.1, 1.1, 0.01)\n",
        "    xx, yy = np.meshgrid(mesh, mesh)\n",
        "    with torch.no_grad():\n",
        "        data = torch.from_numpy(np.vstack((xx.reshape(-1), yy.reshape(-1))).T).float()\n",
        "        Z = model(data).detach()\n",
        "    Z = np.argmax(Z, axis=1).reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.3)\n",
        "    plot_data(X, y)\n",
        "\n",
        "\n",
        "def show_scatterplot(X, colors, title=''):\n",
        "    colors = colors.cpu().numpy()\n",
        "    X = X.cpu().numpy()\n",
        "    plt.figure()\n",
        "    plt.axis('equal')\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=colors, s=30)\n",
        "    # plt.grid(True)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "def plot_bases(bases, width=0.04):\n",
        "    bases = bases.cpu()\n",
        "    bases[2:] -= bases[:2]\n",
        "    plt.arrow(*bases[0], *bases[2], width=width, color=(1,0,0), zorder=10, alpha=1., length_includes_head=True)\n",
        "    plt.arrow(*bases[1], *bases[3], width=width, color=(0,1,0), zorder=10, alpha=1., length_includes_head=True)\n",
        "\n",
        "\n",
        "def show_mat(mat, vect, prod, threshold=-1):\n",
        "    # Subplot grid definition\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=False, sharey=True,\n",
        "                                        gridspec_kw={'width_ratios':[5,1,1]})\n",
        "    # Plot matrices\n",
        "    cax1 = ax1.matshow(mat.numpy(), clim=(-1, 1))\n",
        "    ax2.matshow(vect.numpy(), clim=(-1, 1))\n",
        "    cax3 = ax3.matshow(prod.numpy(), clim=(threshold, 1))\n",
        "\n",
        "    # Set titles\n",
        "    ax1.set_title(f'A: {mat.size(0)} \\u00D7 {mat.size(1)}')\n",
        "    ax2.set_title(f'a^(i): {vect.numel()}')\n",
        "    ax3.set_title(f'p: {prod.numel()}')\n",
        "\n",
        "    # Remove xticks for vectors\n",
        "    ax2.set_xticks(tuple())\n",
        "    ax3.set_xticks(tuple())\n",
        "    \n",
        "    # Plot colourbars\n",
        "    fig.colorbar(cax1, ax=ax2)\n",
        "    fig.colorbar(cax3, ax=ax3)\n",
        "\n",
        "    # Fix y-axis limits\n",
        "    ax1.set_ylim(bottom=max(len(prod), len(vect)) - 0.5)\n",
        "\n",
        "\n",
        "colors = dict(\n",
        "    aqua='#8dd3c7',\n",
        "    yellow='#ffffb3',\n",
        "    lavender='#bebada',\n",
        "    red='#fb8072',\n",
        "    blue='#80b1d3',\n",
        "    orange='#fdb462',\n",
        "    green='#b3de69',\n",
        "    pink='#fccde5',\n",
        "    grey='#d9d9d9',\n",
        "    violet='#bc80bd',\n",
        "    unk1='#ccebc5',\n",
        "    unk2='#ffed6f',\n",
        ")\n",
        "\n",
        "\n",
        "def _cstr(s, color='black'):\n",
        "    if s == ' ':\n",
        "        return f'<text style=color:#000;padding-left:10px;background-color:{color}> </text>'\n",
        "    else:\n",
        "        return f'<text style=color:#000;background-color:{color}>{s} </text>'\n",
        "\n",
        "# print html\n",
        "def _print_color(t):\n",
        "    display(HTML(''.join([_cstr(ti, color=ci) for ti, ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def _get_clr(value):\n",
        "    colors = ('#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
        "              '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "              '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "              '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e')\n",
        "    value = int((value * 100) / 5)\n",
        "    if value == len(colors): value -= 1  # fixing bugs...\n",
        "    return colors[value]\n",
        "\n",
        "def _visualise_values(output_values, result_list):\n",
        "    text_colours = []\n",
        "    for i in range(len(output_values)):\n",
        "        text = (result_list[i], _get_clr(output_values[i]))\n",
        "        text_colours.append(text)\n",
        "    _print_color(text_colours)\n",
        "\n",
        "def print_colourbar():\n",
        "    color_range = torch.linspace(-2.5, 2.5, 20)\n",
        "    to_print = [(f'{x:.2f}', _get_clr((x+2.5)/5)) for x in color_range]\n",
        "    _print_color(to_print)\n",
        "\n",
        "\n",
        "# Let's only focus on the last time step for now\n",
        "# First, the cell state (Long term memory)\n",
        "def plot_state(data, state, b, decoder):\n",
        "    actual_data = decoder(data[b, :, :].numpy())\n",
        "    seq_len = len(actual_data)\n",
        "    seq_len_w_pad = len(state)\n",
        "    for s in range(state.size(2)):\n",
        "        states = torch.sigmoid(state[:, b, s])\n",
        "        _visualise_values(states[seq_len_w_pad - seq_len:], list(actual_data))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDJCR6601pkT"
      },
      "source": [
        "## Autograd: automatic differentiation\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlj-gCJK0Oe0"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WQGs2JL1w7p",
        "outputId": "6a93957c-903f-4ce2-9e0c-5a48510807d6"
      },
      "source": [
        "# Create a 2x2 tensor with gradient-accumulation capabilities\n",
        "x = torch.tensor([[1,2],\n",
        "                  [3,4]], requires_grad = True,\n",
        "                 dtype= torch.float32)\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbN4QwRJ1-8c",
        "outputId": "da86c51b-a8a3-4243-e7b9-b8fb4c86b0dd"
      },
      "source": [
        "# Deduct 2 from all elements\n",
        "\n",
        "y = x -2\n",
        "print(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTcH9bpy2Nbc",
        "outputId": "c25c8e34-d1d0-4130-ce36-fd543b885f67"
      },
      "source": [
        "# y was created as a result of an operation so it has a grad_fn\n",
        "print(y.grad_fn)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SubBackward0 object at 0x7f6f9595e048>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAThLYWd2W-O",
        "outputId": "9d598197-ac75-449e-90c5-0b084764fcc2"
      },
      "source": [
        "# What's happening here?\n",
        "print(x.grad_fn)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oap8pGck2dmy",
        "outputId": "673adefc-f46e-4460-8c92-0e547b8fd89c"
      },
      "source": [
        "# Let's dig further\n",
        "y.grad_fn"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SubBackward0 at 0x7f6f95976f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u37oKNyo2jjD",
        "outputId": "b273617a-ffaf-475a-de87-b8e7ce690bcf"
      },
      "source": [
        "y.grad_fn.next_functions[0][0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AccumulateGrad at 0x7f6f95a0ccf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkWIu-W-2nga",
        "outputId": "881418f3-48d4-461e-efc0-dee4283d83e8"
      },
      "source": [
        "y.grad_fn.next_functions[0][0].variable"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHudSqCX2rxF",
        "outputId": "d74e3235-58a1-42e2-e409-6e769d2ffe92"
      },
      "source": [
        "# Do more operations on y\n",
        "\n",
        "z = y * y * 3\n",
        "a = z.mean() # average\n",
        "\n",
        "print(z)\n",
        "print(a)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3.,  0.],\n",
            "        [ 3., 12.]], grad_fn=<MulBackward0>)\n",
            "tensor(4.5000, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcTLJhzp3I-m",
        "outputId": "f43d158e-76c0-4047-cf35-3b704c9e2369"
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.7.0+cu101)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.7)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=d54982410c406b309836e2a9131e5f31d78ec87ae5fe38290ca383e77e234ea9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "TdE3pn6n2817",
        "outputId": "bb978558-e629-4450-d8c1-d56be5432d08"
      },
      "source": [
        "# Let's visualise the computational graph! (thks @szagoruyko)\n",
        "from torchviz import make_dot\n",
        "make_dot(a)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f6f9595e8d0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"106pt\" height=\"271pt\"\n viewBox=\"0.00 0.00 106.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-267 102,-267 102,4 -4,4\"/>\n<!-- 140117227725880 -->\n<g id=\"node1\" class=\"node\">\n<title>140117227725880</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"98,-21 0,-21 0,0 98,0 98,-21\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 140117227726440 -->\n<g id=\"node2\" class=\"node\">\n<title>140117227726440</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"94.5,-78 3.5,-78 3.5,-57 94.5,-57 94.5,-78\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140117227726440&#45;&gt;140117227725880 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140117227726440&#45;&gt;140117227725880</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M49,-56.7787C49,-49.6134 49,-39.9517 49,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"52.5001,-31.1732 49,-21.1732 45.5001,-31.1732 52.5001,-31.1732\"/>\n</g>\n<!-- 140117227725488 -->\n<g id=\"node3\" class=\"node\">\n<title>140117227725488</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"94.5,-135 3.5,-135 3.5,-114 94.5,-114 94.5,-135\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140117227725488&#45;&gt;140117227726440 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140117227725488&#45;&gt;140117227726440</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M49,-113.7787C49,-106.6134 49,-96.9517 49,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"52.5001,-88.1732 49,-78.1732 45.5001,-88.1732 52.5001,-88.1732\"/>\n</g>\n<!-- 140117227827040 -->\n<g id=\"node4\" class=\"node\">\n<title>140117227827040</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"94,-192 4,-192 4,-171 94,-171 94,-192\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 140117227827040&#45;&gt;140117227725488 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140117227827040&#45;&gt;140117227725488</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M43.5885,-170.7787C42.3317,-163.6134 41.9599,-153.9517 42.4733,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"45.9738,-145.498 43.597,-135.1732 39.0164,-144.7267 45.9738,-145.498\"/>\n</g>\n<!-- 140117227827040&#45;&gt;140117227725488 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140117227827040&#45;&gt;140117227725488</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4115,-170.7787C55.6683,-163.6134 56.0401,-153.9517 55.5267,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"58.9836,-144.7267 54.403,-135.1732 52.0262,-145.498 58.9836,-144.7267\"/>\n</g>\n<!-- 140117228440824 -->\n<g id=\"node5\" class=\"node\">\n<title>140117228440824</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"76,-263 22,-263 22,-228 76,-228 76,-263\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (2, 2)</text>\n</g>\n<!-- 140117228440824&#45;&gt;140117227827040 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140117228440824&#45;&gt;140117227827040</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M49,-227.6724C49,-219.8405 49,-210.5893 49,-202.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"52.5001,-202.2234 49,-192.2234 45.5001,-202.2235 52.5001,-202.2234\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYJ9QRlE3VDO"
      },
      "source": [
        "## Gradients\n",
        "Let's backprop now out.backward() is equivalent to doing out.backward(torch.tensor([1.0]))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8gKfqt43FsE"
      },
      "source": [
        "# Backprop\n",
        "a.backward()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sU3rf7i4WHx"
      },
      "source": [
        "Print gradients $\\frac{\\text{d}a}{\\text{d}x}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wdw5UFu4zS4",
        "outputId": "632366ed-d8ff-487f-abb7-b0c74bf39f6e"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFaoDl_K4UJ3",
        "outputId": "1d9e6c13-964b-408f-93fa-7febcb97e3f5"
      },
      "source": [
        "# Compute it by hand BEFORE executing this\n",
        "print(x.grad)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.5000,  0.0000],\n",
            "        [ 1.5000,  3.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB0vawaj45z4"
      },
      "source": [
        "You can do many crazy things with autograd!\n",
        "\n",
        "With Great Flexibility Comes Great Responsibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3ci7U0u4jhd",
        "outputId": "7fa4ddfc-2e35-44e6-b497-6bf264b60d50"
      },
      "source": [
        "# Dynamic Graphs!\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "i = 0\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "    i += 1\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-172.2352, 1070.2888,  642.4351], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzmVl8eX5TJk",
        "outputId": "0135fe7e-9494-4405-e2ad-27a039cc8d5a"
      },
      "source": [
        "# If we don't run backward on a scalar we need to specify the grad_output\n",
        "\n",
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zTc6g-_5pHL",
        "outputId": "7a92a3fd-0543-4e4a-b7d8-5721b33afb4e"
      },
      "source": [
        "# BEFORE executing this, can you tell what would you expect it to print?\n",
        "print(i)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIl9sS206s-y"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOk451Vj6jff"
      },
      "source": [
        "# This variable decides the tensor's range below\n",
        "n = 3"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiuaCr_g609V",
        "outputId": "a027febc-f1cd-43f1-9643-9ab8faa7b08a"
      },
      "source": [
        "# Both x and w that allows gradient accumulation\n",
        "x = torch.arange(1., n+1, requires_grad=True)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "print(x)\n",
        "print(w)\n",
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], requires_grad=True)\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "tensor([1., 1., 1.])\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0VbU0KV7Twp",
        "outputId": "50700f9c-e906-4b6b-de25-2f929f663ff3"
      },
      "source": [
        "# Only w that allows gradient accumulation\n",
        "x = torch.arange(1., n+1)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "print(x)\n",
        "print(w)\n",
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "None\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvy3avUh8D3d",
        "outputId": "3533466b-e88d-41bf-9cfd-0d065e08b976"
      },
      "source": [
        "x = torch.arange(1., n + 1)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "\n",
        "# Regardless of what you do in this context, all torch tensors will not have gradient accumulation\n",
        "with torch.no_grad():\n",
        "    z = w @ x\n",
        "\n",
        "try:\n",
        "    z.backward() # PyTorch will throw an error here, since z has no grad accum.\n",
        "\n",
        "except RuntimeError as e:\n",
        "    print('Runtime Error! >:[')\n",
        "    print(e)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Runtime Error! >:[\n",
            "element 0 of tensors does not require grad and does not have a grad_fn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmUIupZq8m5-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}